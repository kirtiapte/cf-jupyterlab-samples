{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff72f76-959e-4420-8e7d-8abde272ee9f",
   "metadata": {},
   "source": [
    "## FinSmart Rag Based Assistant\n",
    "- Langchain based RAG assistant using PgVectorstore\n",
    "- Provide context-aware, explainable answers from the company’s data.\n",
    "- Help financial advisors and customers query portfolio and transaction data in natural language.\n",
    "- Maintain data privacy and compliance while delivering AI-powered insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0dfd3b-ff1c-46b4-bec6-129aea7322d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ transactions.csv created with 5 records.\n",
      "✅ portfolio.csv created with 5 records.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Transactions CSV\n",
    "# -----------------------------\n",
    "transactions_data = [\n",
    "    {\"transaction_id\": \"T001\", \"user_id\": \"U100\", \"date\": \"2025-06-15\", \"category\": \"Deposit\",\n",
    "     \"description\": \"Paycheck deposit from employer\", \"amount\": 3500.00, \"balance\": 12500.00},\n",
    "    {\"transaction_id\": \"T002\", \"user_id\": \"U100\", \"date\": \"2025-06-20\", \"category\": \"Investment\",\n",
    "     \"description\": \"Purchased 10 shares of AAPL\", \"amount\": -1800.00, \"balance\": 10700.00},\n",
    "    {\"transaction_id\": \"T003\", \"user_id\": \"U100\", \"date\": \"2025-07-05\", \"category\": \"Expense\",\n",
    "     \"description\": \"Rent payment\", \"amount\": -2500.00, \"balance\": 8200.00},\n",
    "    {\"transaction_id\": \"T004\", \"user_id\": \"U100\", \"date\": \"2025-07-10\", \"category\": \"Dividend\",\n",
    "     \"description\": \"Dividend from VTI ETF\", \"amount\": 120.00, \"balance\": 8320.00},\n",
    "    {\"transaction_id\": \"T005\", \"user_id\": \"U100\", \"date\": \"2025-07-18\", \"category\": \"Expense\",\n",
    "     \"description\": \"Grocery shopping\", \"amount\": -200.00, \"balance\": 8120.00},\n",
    "]\n",
    "\n",
    "transactions_df = pd.DataFrame(transactions_data)\n",
    "transactions_df.to_csv(\"transactions.csv\", index=False)\n",
    "print(\"✅ transactions.csv created with 5 records.\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Portfolio CSV\n",
    "# -----------------------------\n",
    "portfolio_data = [\n",
    "    {\"portfolio_id\": \"P001\", \"user_id\": \"U100\", \"symbol\": \"AAPL\", \"company_name\": \"Apple Inc.\",\n",
    "     \"shares\": 25, \"avg_buy_price\": 175.00, \"current_price\": 189.50, \"sector\": \"Technology\", \"risk_level\": \"Medium\"},\n",
    "    {\"portfolio_id\": \"P002\", \"user_id\": \"U100\", \"symbol\": \"VTI\", \"company_name\": \"Vanguard Total Stock Market ETF\",\n",
    "     \"shares\": 40, \"avg_buy_price\": 220.00, \"current_price\": 229.50, \"sector\": \"Index Fund\", \"risk_level\": \"Low\"},\n",
    "    {\"portfolio_id\": \"P003\", \"user_id\": \"U100\", \"symbol\": \"MSFT\", \"company_name\": \"Microsoft Corp.\",\n",
    "     \"shares\": 15, \"avg_buy_price\": 315.00, \"current_price\": 330.00, \"sector\": \"Technology\", \"risk_level\": \"Medium\"},\n",
    "    {\"portfolio_id\": \"P004\", \"user_id\": \"U100\", \"symbol\": \"TSLA\", \"company_name\": \"Tesla Inc.\",\n",
    "     \"shares\": 5, \"avg_buy_price\": 260.00, \"current_price\": 250.00, \"sector\": \"Automotive\", \"risk_level\": \"High\"},\n",
    "    {\"portfolio_id\": \"P005\", \"user_id\": \"U100\", \"symbol\": \"GOOGL\", \"company_name\": \"Alphabet Inc.\",\n",
    "     \"shares\": 10, \"avg_buy_price\": 140.00, \"current_price\": 150.00, \"sector\": \"Technology\", \"risk_level\": \"Medium\"},\n",
    "]\n",
    "\n",
    "portfolio_df = pd.DataFrame(portfolio_data)\n",
    "portfolio_df.to_csv(\"portfolio.csv\", index=False)\n",
    "print(\"✅ portfolio.csv created with 5 records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a5070a7-af26-406a-ab2e-6e65eca06fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- nomic-embed-text-v1025 (capabilities: EMBEDDING)\n",
      "Embedding model: nomic-embed-text-v1025\n"
     ]
    }
   ],
   "source": [
    "## Ingestion pipeline to load data\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import httpx\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from cfenv import AppEnv\n",
    "import sys, os\n",
    "import warnings\n",
    "\n",
    "# go one level up from cflangchainfolder/ to project root\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from cfutils import CFGenAIService\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# -----------------------------\n",
    "# Load services from env\n",
    "# -----------------------------\n",
    "env = AppEnv()\n",
    "\n",
    "# -----------------------------\n",
    "# Embedding service details\n",
    "# -----------------------------\n",
    "embedding_service = CFGenAIService(\"tanzu-nomic-embed-text\")\n",
    "\n",
    "# List available models\n",
    "embedding_models = embedding_service.list_models()\n",
    "for m in embedding_models:\n",
    "    print(f\"- {m['name']} (capabilities: {', '.join(m['capabilities'])})\")\n",
    "\n",
    "\n",
    "api_base = embedding_service.api_base + \"/\n",
    "api_key = embedding_service.api_key\n",
    "model_name = embedding_models[0][\"name\"]\n",
    "\n",
    "print(\"Embedding model:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a6555c-e633-4dea-926b-630d9dc73312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB URI: postgresql://pgadmin:629PVy514m0w8rc3jq7Y@q-s0.postgres-instance.kdc01-dvs-lab-mgt-net-82.service-instance-465d60d4-e494-49a5-aace-022e92fbdc1c.bosh:5432/postgres\n",
      "Connected to: PostgreSQL 16.6 (VMware Postgres 16.6.0) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Database connection\n",
    "# -----------------------------\n",
    "db_service = env.get_service(name=\"vector-db\")\n",
    "db_credentials = db_service.credentials\n",
    "db_uri = db_credentials[\"uri\"]\n",
    "\n",
    "print(\"DB URI:\", db_uri)\n",
    "\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "# Test DB connection\n",
    "with engine.connect() as conn:\n",
    "    version = conn.execute(text(\"SELECT version();\")).fetchone()\n",
    "    print(\"Connected to:\", version[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab120b57-3dcd-4e46-b74a-8344bde631c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Embedding function (REST call)\n",
    "# -----------------------------\n",
    "url = api_base + \"/embeddings\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "def embed_text(text: str):\n",
    "    payload = {\"model\": model_name, \"input\": text}\n",
    "    resp = requests.post(url, headers=headers, json=payload, verify=False)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "class CustomEmbeddings:\n",
    "    def embed_documents(self, texts): return [embed_text(t) for t in texts]\n",
    "    def embed_query(self, text): return embed_text(text)\n",
    "\n",
    "embedding = CustomEmbeddings()\n",
    "\n",
    "# -----------------------------\n",
    "# PGVector setup\n",
    "# -----------------------------\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embedding,\n",
    "    connection=db_uri,\n",
    "    collection_name=\"finsmart-transactions\",\n",
    "    use_jsonb=True,\n",
    "    create_extension=True,       # will create pgvector extension if not exists\n",
    "    pre_delete_collection=True,  # clears old data on restart\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Load maintenance.csv\n",
    "# -----------------------------\n",
    "def sanitize_metadata(metadata):\n",
    "    sanitized = {}\n",
    "    for k, v in metadata.items():\n",
    "        if isinstance(v, set):\n",
    "            sanitized[k] = list(v)\n",
    "        elif not isinstance(v, (str, int, float, bool, dict, list, type(None))):\n",
    "            sanitized[k] = str(v)\n",
    "        else:\n",
    "            sanitized[k] = v\n",
    "    return sanitized\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load transactions.csv\n",
    "# -----------------------------\n",
    "df_transactions = pd.read_csv(\"transactions.csv\")  # columns: transaction_id, user_id, date, category, description, amount, balance\n",
    "\n",
    "docs_transactions = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            f\"Transaction {row['transaction_id']} ({row['category']}): \"\n",
    "            f\"{row['description']} of ${row['amount']} on {row['date']}. \"\n",
    "            f\"Account balance after transaction: ${row['balance']}.\"\n",
    "        ),\n",
    "        metadata=sanitize_metadata({\n",
    "            \"id\": row[\"transaction_id\"],\n",
    "            \"user_id\": row[\"user_id\"],\n",
    "            \"source\": \"transactions.csv\"\n",
    "        })\n",
    "    )\n",
    "    for _, row in df_transactions.iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load portfolio.csv\n",
    "# -----------------------------\n",
    "df_portfolio = pd.read_csv(\"portfolio.csv\")  # columns: portfolio_id, user_id, symbol, company_name, shares, avg_buy_price, current_price, sector, risk_level\n",
    "\n",
    "docs_portfolio = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            f\"Portfolio {row['portfolio_id']} holding {row['shares']} shares of {row['company_name']} ({row['symbol']}). \"\n",
    "            f\"Average buy price ${row['avg_buy_price']}, current price ${row['current_price']}. \"\n",
    "            f\"Sector: {row['sector']}, risk level: {row['risk_level']}.\"\n",
    "        ),\n",
    "        metadata=sanitize_metadata({\n",
    "            \"id\": row[\"portfolio_id\"],\n",
    "            \"user_id\": row[\"user_id\"],\n",
    "            \"source\": \"portfolio.csv\"\n",
    "        })\n",
    "    )\n",
    "    for _, row in df_portfolio.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b89227b1-16bb-40fb-873b-29a4b7d7881e",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://genai-proxy.sys.tas-ndc.kuhn-labs.com/tanzu-nomic-embed-text-v1025-4201d1d/v1/embeddings",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Insert into vectorstore\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      4\u001b[39m all_financial_docs = docs_transactions + docs_portfolio\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_financial_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Inserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents into the vectorstore!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Inspect DB\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:279\u001b[39m, in \u001b[36mVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m     texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    278\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m msg = (\n\u001b[32m    281\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    283\u001b[39m )\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/langchain_postgres/vectorstores.py:885\u001b[39m, in \u001b[36mPGVector.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_engine, \u001b[33m\"\u001b[39m\u001b[33mThis method must be called without async_mode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    884\u001b[39m texts_ = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add_embeddings(\n\u001b[32m    887\u001b[39m     texts=texts_,\n\u001b[32m    888\u001b[39m     embeddings=\u001b[38;5;28mlist\u001b[39m(embeddings),\n\u001b[32m   (...)\u001b[39m\u001b[32m    891\u001b[39m     **kwargs,\n\u001b[32m    892\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mCustomEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts): \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36membed_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      8\u001b[39m payload = {\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model_name, \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: text}\n\u001b[32m      9\u001b[39m resp = requests.post(url, headers=headers, json=payload, verify=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp.json()[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://genai-proxy.sys.tas-ndc.kuhn-labs.com/tanzu-nomic-embed-text-v1025-4201d1d/v1/embeddings"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Insert into vectorstore\n",
    "# -----------------------------\n",
    "all_financial_docs = docs_transactions + docs_portfolio\n",
    "vectorstore.add_documents(all_financial_docs)\n",
    "\n",
    "print(f\"✅ Inserted {len(all_docs)} documents into the vectorstore!\")\n",
    "\n",
    "# -----------------------------\n",
    "# Inspect DB\n",
    "# -----------------------------\n",
    "query = text(\"SELECT * FROM langchain_pg_collection LIMIT 5;\")\n",
    "print(pd.read_sql(query, engine))\n",
    "\n",
    "query2 = text(\"SELECT * FROM langchain_pg_embedding LIMIT 5;\")\n",
    "print(pd.read_sql(query2, engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5061c8c4-4825-481c-ad9e-fa0caeab9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- openai/gpt-oss-120b (capabilities: CHAT, TOOLS)\n",
      "chat model: nomic-embed-text-v1025https://genai-proxy.sys.tas-ndc.kuhn-labs.com/tanzu-nomic-embed-text-v1025-4201d1d/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from datetime import date\n",
    "import warnings\n",
    "import ssl\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Optional: configure custom http client\n",
    "httpx_client = httpx.Client(http2=True, verify=False, timeout=30.0)\n",
    "# Load CF environment\n",
    "# -----------------------------\n",
    "# Load services from env\n",
    "# -----------------------------\n",
    "env = AppEnv()\n",
    "\n",
    "# -----------------------------\n",
    "# cat service details\n",
    "# -----------------------------\n",
    "chat_service = CFGenAIService(\"tanzu-gpt-oss-120b\")\n",
    "\n",
    "# List available models\n",
    "chat_models = chat_service.list_models()\n",
    "for m in chat_models:\n",
    "    print(f\"- {m['name']} (capabilities: {', '.join(m['capabilities'])})\")\n",
    "\n",
    "\n",
    "chat_api_base = chat_service.api_base\n",
    "chat_api_key = chat_service.api_key\n",
    "chat_model_name = chat_models[0][\"name\"]\n",
    "\n",
    "print(\"chat model:\", model_name + api_base)\n",
    "\n",
    "# Initialize LLM with credentials from cfenv\n",
    "chat_llm = ChatOpenAI(\n",
    "    temperature=0.9,\n",
    "    model=chat_model_name,\n",
    "    base_url=chat_api_base,\n",
    "    api_key=chat_api_key,\n",
    "    http_client=httpx_client\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f433c14-68e8-4de3-9f46-1d221f4107d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from your vectorstore\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "\n",
    "# Build a RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=chat_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "query = \"Summarize my recent expenses and how my Apple and Microsoft investments are performing?\"\n",
    "result = qa.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b03aca-bf93-458d-9782-d3550221ecad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
