{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96cfdbd7-96fd-4cd5-a788-50334cb1fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/vcap/deps/0/python/lib/python3.11/site-packages (25.1.1)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in /home/vcap/deps/0/python/lib/python3.11/site-packages (2.0.10)\n",
      "Requirement already satisfied: aiosqlite>=0.20 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.21.0)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.21 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (2.1.1)\n",
      "Requirement already satisfied: sqlite-vec>=0.1.6 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.1.6)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from aiosqlite>=0.20->langgraph-checkpoint-sqlite) (4.14.1)\n",
      "Requirement already satisfied: langchain-core>=0.2.38 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.3.69)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.10.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint>=2.0.21->langgraph-checkpoint-sqlite) (1.3.1)\n",
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n",
      "[AIMessage(content='<think>\\nOkay, the user is asking for the weather in Austin. I need to figure out how to get that information. Let me check the tools available. There\\'s a function called tavily_search_results_json which is a search engine. Maybe I can use that to look up the current weather in Austin. The function requires a query parameter, so I should structure the search query as \"current weather in Austin\". That should fetch the necessary information. I\\'ll make sure to call the function correctly with the query term.\\n</think>\\n\\n', additional_kwargs={'tool_calls': [{'id': '', 'function': {'arguments': '{\"query\":\"current weather in Austin\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 243, 'total_tokens': 376, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen3-30b-a3b-ultra', 'system_fingerprint': 'tanzuAiServer', 'id': '', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--78b7f0ba-d6ba-460a-a253-c6700376ae00-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Austin'}, 'id': '', 'type': 'tool_call'}], usage_metadata={'input_tokens': 243, 'output_tokens': 133, 'total_tokens': 376, 'input_token_details': {}, 'output_token_details': {}})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Austin'}, 'id': '', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content=\"[{'title': 'Weather Forecast and Conditions for Austin, TX', 'url': 'https://weather.com/weather/today/l/Austin+TX?canonicalCityId=1692e49f355e6f12c77810b1ab153c25', 'content': 'A mix of clouds and sun. High 96F. Winds S at 10 to 15 mph. Humidity58%. UV IndexExtreme. Sunrise6:43 am. Sunset', 'score': 0.986}, {'title': 'July 22nd midday with Meteorologist Grace Thornton - Austin - KVUE', 'url': 'https://www.kvue.com/video/weather/forecast/austin-area-weather-july-22nd-midday-with-meteorologist-grace-thornton/269-f9107b86-5728-4115-87ac-9f9d5c7ff0e0', 'content': 'Example video title will go here for this video. Hot and humid. Author: kvue.com. Published: 12:21 PM CDT July 22, 2025. Updated: 12:23 PM CDT July 22, 2025.', 'score': 0.98547}]\", name='tavily_search_results_json', tool_call_id='')]\n",
      "[AIMessage(content='<think>\\nOkay, let\\'s see. The user asked for the weather in Austin. I used the tavily_search_results_json function to look it up. The response has two entries. The first one is from a weather website, listing the current conditions. The content says \"A mix of clouds and sun. High 96F. Winds S at 10 to 15 mph. Humidity 58%. UV Index Extreme. Sunrise 6:43 am. Sunset...\" So that\\'s the current forecast. The second entry is a video from KVUE about the Austin weather, but the date is July 22, 2025, which is a future date. That might be a placeholder or example. The user probably wants the current weather, so I should focus on the first result. The answer should include the high temperature, clouds, sun, wind speed, humidity, and UV index. I need to present it clearly, maybe in a summary. Also, check if the dates make sense. The second result\\'s date is in the future, which might not be relevant. So the main info is from the first result. I\\'ll format that into a concise answer.\\n</think>\\n\\nThe current weather in Austin, TX is a mix of clouds and sun with a high of **96°F**. Additional conditions include:\\n- **Winds**: S at 10–15 mph\\n- **Humidity**: 58%\\n- **UV Index**: Extreme\\n- **Sunrise**: 6:43 am\\n- **Sunset**: Not listed (likely incomplete in the source)\\n\\nFor real-time updates, check a dedicated weather service like [Weather.com](https://weather.com).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 352, 'prompt_tokens': 664, 'total_tokens': 1016, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'qwen3-30b-a3b-ultra', 'system_fingerprint': 'tanzuAiServer', 'id': '', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--32ef7211-5b37-4b65-b411-836ae787ab5f-0', usage_metadata={'input_tokens': 664, 'output_tokens': 352, 'total_tokens': 1016, 'input_token_details': {}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!pip3 install -qU langgraph\n",
    "!pip3 install langgraph-checkpoint-sqlite\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from tavily import TavilyClient\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# connect to tavily search tool\n",
    "os.environ['TAVILY_API_KEY']=\"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\"\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "#define agent state\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "#memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "print(type(tool))\n",
    "print(tool.name)\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}\n",
    "\n",
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "# configure model\n",
    "httpx_client = httpx.Client(http2=True, verify=False, timeout=10.0)\n",
    "\n",
    "vcapservices = os.getenv('VCAP_SERVICES')\n",
    "services = json.loads(vcapservices)\n",
    "\n",
    "def is_chatservice(service):\n",
    "    return service[\"name\"] == \"gen-ai-qwen3-ultra\"\n",
    "\n",
    "chat_services = filter(is_chatservice, services[\"genai\"])\n",
    "chat_credentials = list(chat_services)[0][\"credentials\"]\n",
    "\n",
    "model = ChatOpenAI(temperature=0.9, model=chat_credentials[\"model_name\"], base_url=chat_credentials[\"api_base\"], api_key=chat_credentials[\"api_key\"], http_client=httpx_client)\n",
    "messages = [HumanMessage(content=\"What is the weather in Austin?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    abot = Agent(model, [tool], system=prompt, checkpointer=checkpointer)\n",
    "    for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "        for v in event.values():\n",
    "            print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f910ed-cd21-432c-878d-c3fd0e0b66e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba3dd7-5f18-47e8-9ce3-72e8966ff5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a5a21-8c52-488e-944a-2368d93624cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
