{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b0f92-e9cd-49d2-85fe-08a803e29513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/vcap/deps/0/python/lib/python3.11/site-packages (25.1.1)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in /home/vcap/deps/0/python/lib/python3.11/site-packages (2.0.11)\n",
      "Requirement already satisfied: aiosqlite>=0.20 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.21.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.21 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (2.1.1)\n",
      "Requirement already satisfied: sqlite-vec>=0.1.6 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.1.6)\n",
      "Requirement already satisfied: langchain-core>=0.2.38 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.3.69)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from aiosqlite>=0.20->langgraph-checkpoint-sqlite) (4.14.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.21->langgraph-checkpoint-sqlite) (1.3.1)\n",
      "Requirement already satisfied: tavily-python in /home/vcap/deps/0/python/lib/python3.11/site-packages (0.7.10)\n",
      "Requirement already satisfied: requests in /home/vcap/deps/0/python/lib/python3.11/site-packages (from tavily-python) (2.32.4)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from tavily-python) (0.9.0)\n",
      "Requirement already satisfied: httpx in /home/vcap/deps/0/python/lib/python3.11/site-packages (from tavily-python) (0.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests->tavily-python) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests->tavily-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests->tavily-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from requests->tavily-python) (2025.7.14)\n",
      "Requirement already satisfied: anyio in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx->tavily-python) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpx->tavily-python) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/vcap/deps/0/python/lib/python3.11/site-packages (from anyio->httpx->tavily-python) (4.14.1)\n",
      "{'planner': {'plan': '<think>\\nOkay, the user is asking about the difference between LangChain and LangSmith. Let me start by recalling what each of these tools does. \\n\\nLangChain is a framework for building applications powered by language models. It provides tools to connect different components like data loaders, prompts, models, and output parsers. It\\'s more about the architecture and integration of various parts.\\n\\nLangSmith, on the other hand, is a platform for building, testing, and deploying AI applications. It might offer a more user-friendly interface, maybe with features like version control, collaboration tools, and monitoring. I think it\\'s designed to streamline the development process with a focus on productivity and team collaboration.\\n\\nNow, I need to structure the essay. The user wants an outline with sections and notes. Let me think about the main sections. Probably an introduction, then sections on each tool, their key features, use cases, and a comparison. Also, a conclusion.\\n\\nWait, the user mentioned \"high level outline of an essay\". So the outline should have sections and subsections. Let me make sure each part is clear. \\n\\nIn the introduction, I should define both tools and state the purpose of the essay. Then, for each tool, explain what they are, their key features, and their target audience. Then a dedicated section for comparing them, highlighting differences in purpose, functionality, user experience, and use cases. Finally, a conclusion summarizing the key points.\\n\\nNotes for each section: For LangChain, emphasize its framework aspects, flexibility, and integration. For LangSmith, focus on its platform features, ease of use, and collaboration. In the comparison, highlight the main differences like framework vs. platform, customization vs. user-friendliness, etc.\\n\\nI should check if there are any common misconceptions. Maybe some people think they\\'re similar, but they serve different roles. Also, mention that LangChain is more for developers needing customization, while LangSmith is for teams looking for a more integrated solution.\\n\\nMake sure the outline is logical and flows well. Each section builds on the previous one, leading to the comparison. The notes should guide the writer on what to cover in each part without being too detailed.\\n</think>\\n\\n### **Essay Outline: What is the Difference Between LangChain and LangSmith?**\\n\\n---\\n\\n#### **I. Introduction**  \\n- **Purpose**: Introduce the growing importance of AI development tools and the role of LangChain and LangSmith in this ecosystem.  \\n- **Thesis Statement**: While both LangChain and LangSmith are designed to streamline AI application development, they differ significantly in purpose, functionality, and target users.  \\n- **Notes**:  \\n  - Define **LangChain** (a framework for building AI applications) and **LangSmith** (a platform for AI development and deployment).  \\n  - Highlight the relevance of understanding their differences for developers, teams, and organizations.\\n\\n---\\n\\n#### **II. What is LangChain?**  \\n- **Definition**: A modular framework for building AI applications by connecting language models, data sources, and tools.  \\n- **Key Features**:  \\n  - **Modular Architecture**: Allows developers to plug in different components (e.g., prompts, models, outputs).  \\n  - **Flexibility**: Supports custom workflows and integration with external tools.  \\n  - **Developer-Centric**: Designed for developers who need fine-grained control over AI pipelines.  \\n- **Use Cases**:  \\n  - Building complex AI applications (e.g., chatbots, data analysis tools).  \\n  - Prototyping and testing AI workflows.  \\n- **Notes**: Emphasize its role as a \"building block\" for developers, not a full-platform solution.\\n\\n---\\n\\n#### **III. What is LangSmith?**  \\n- **Definition**: A collaborative platform for developing, testing, and deploying AI applications.  \\n- **Key Features**:  \\n  - **User-Friendly Interface**: Designed for teams to work together on AI projects.  \\n  - **Integrated Tools**: Includes features like version control, monitoring, and deployment.  \\n  - **Collaboration Focus**: Streamlines teamwork with shared projects and real-time feedback.  \\n- **Use Cases**:  \\n  - Rapid prototyping of AI applications.  \\n  - Scaling AI solutions with team input and iteration.  \\n- **Notes**: Highlight its role as a \"full-stack\" platform for teams, contrasting with LangChain’s developer-centric approach.\\n\\n---\\n\\n#### **IV. Key Differences Between LangChain and LangSmith**  \\n- **Purpose**:  \\n  - **LangChain**: A framework for building AI applications (developer-focused).  \\n  - **LangSmith**: A platform for collaborative AI development (team-focused).  \\n- **Functionality**:  \\n  - **LangChain**: Emphasizes modularity and customization.  \\n  - **LangSmith**: Focuses on collaboration, deployment, and lifecycle management.  \\n- **User Experience**:  \\n  - **LangChain**: Requires technical expertise (e.g., coding, API integration).  \\n  - **LangSmith**: Designed for teams with less coding, more visual tools.  \\n- **Target Audience**:  \\n  - **LangChain**: Developers and AI engineers.  \\n  - **LangSmith**: Teams, product managers, and non-technical stakeholders.  \\n- **Notes**: Use a table or bullet points to clarify differences.\\n\\n---\\n\\n#### **V. When to Use Each Tool**  \\n- **LangChain**:  \\n  - Ideal for developers creating custom AI workflows.  \\n  - Best for projects requiring high flexibility and integration.  \\n- **LangSmith**:  \\n  - Suitable for teams needing a collaborative, end-to-end AI development platform.  \\n  - Best for rapid iteration, deployment, and team collaboration.  \\n- **Notes**: Provide real-world examples (e.g., a startup using LangChain for a custom chatbot vs. a company using LangSmith for team-based AI projects).\\n\\n---\\n\\n#### **VI. Conclusion**  \\n- **Summary**: Recap the core differences: LangChain as a framework for developers and LangSmith as a platform for teams.  \\n- **Implications**: Emphasize how choosing the right tool depends on project goals, team size, and technical expertise.  \\n- **Final Thought**: Both tools complement each other, with LangChain offering depth and LangSmith providing breadth in AI development.  \\n\\n---\\n\\n### **Notes for Writing the Essay**  \\n1. **Tone**: Academic but accessible; avoid jargon unless explained.  \\n2. **Structure**: Follow the outline, ensuring each section flows logically.  \\n3. **Examples**: Use hypothetical or real-world scenarios to illustrate differences.  \\n4. **Comparisons**: Highlight contrasts in purpose, functionality, and audience.  \\n5. **Citations**: If using specific features of LangChain or LangSmith, reference their official documentation or websites.  \\n\\nLet me know if you’d like help expanding any section!'}}\n",
      "Error parsing JSON from model output: No JSON object found in response\n",
      "{'research_plan': {'content': []}}\n",
      "{'generate': {'draft': '<think>\\nOkay, the user is asking about the difference between LangChain and LangSmith. Let me start by recalling what I know about these tools. From the previous outline, I see that LangChain is a framework for building AI applications, focusing on modularity and flexibility. LangSmith, on the other hand, is a platform aimed at teams, offering collaboration features and a more user-friendly interface.\\n\\nThe user provided an outline with sections like Introduction, What is LangChain, What is LangSmith, Key Differences, and Conclusion. The initial essay I wrote followed that structure. Now, the user might want a more detailed or refined version. But since they haven\\'t provided specific feedback yet, I should check if there\\'s anything missing.\\n\\nWait, the user\\'s initial query was \"what is the difference between langchain and langsmith,\" and the assistant provided an outline. Now, the user might be expecting the actual essay based on that outline. But in the current context, the user hasn\\'t given a specific request beyond the outline. However, looking at the history, the user might be looking for the final essay. But in the current prompt, the user hasn\\'t provided a specific request beyond the outline. Hmm.\\n\\nWait, the user\\'s message says: \"Here is my plan: [then the outline]. Please write the essay.\" But in the current query, the user hasn\\'t actually provided the outline. Wait, no, looking back, the user\\'s message starts with \"Here is my plan:\" followed by the outline. But in the current context, the user is asking for the essay based on that outline. However, in the initial interaction, the user might have provided the outline, and the assistant is to generate the essay. But in the current context, the user hasn\\'t provided the outline. Wait, no, the user\\'s message is the outline. Let me check again.\\n\\nWait, the user\\'s message is: \"what is the difference between langchain and langsmith. Here is my plan: [then the outline]. Please write the essay.\" But in the current context, the user hasn\\'t provided the outline. Wait, no, the user\\'s message is the outline. Wait, the user\\'s message is the outline. Let me check again.\\n\\nWait, the user\\'s message starts with \"what is the difference between langchain and langsmith\" and then says \"Here is my plan:\" followed by the outline. So the user is providing the outline and asking for the essay. But in the current context, the user is asking for the essay based on the outline they provided. However, in the initial prompt, the user might have provided the outline, and the assistant is to generate the essay. But in the current context, the user hasn\\'t provided the outline. Wait, no, the user\\'s message includes the outline. Let me check again.\\n\\nWait, the user\\'s message is: \"what is the difference between langchain and langsmith. Here is my plan: [then the outline]. Please write the essay.\" So the user is providing the outline and asking for the essay. However, in the current context, the user\\'s message is the outline. But in the initial prompt, the user might have provided the outline, and the assistant is to generate the essay. However, in the current context, the user is asking for the essay based on the outline they provided. Therefore, the assistant should generate the essay based on the outline provided.\\n\\nBut in the current context, the user\\'s message is the outline. So the assistant needs to generate the essay based on that outline. The user\\'s message includes the outline, so the assistant should write the essay as per the outline. The previous response was the outline, and the user is now asking for the essay. Therefore, the assistant should generate the essay based on the outline provided.\\n</think>\\n\\n**Essay: What is the Difference Between LangChain and LangSmith?**\\n\\nIn the rapidly evolving landscape of artificial intelligence, tools like **LangChain** and **LangSmith** have emerged to simplify the development of AI applications. While both platforms aim to streamline AI workflows, they serve distinct purposes and cater to different user needs. This essay explores the key differences between LangChain and LangSmith, focusing on their design philosophies, target audiences, and use cases.\\n\\n**What is LangChain?**  \\nLangChain is a **framework** designed for developers who want to build AI applications by connecting language models, data sources, and tools. It emphasizes **modularity** and **flexibility**, allowing users to create custom workflows tailored to specific tasks. For instance, a developer might use LangChain to build a chatbot that integrates a language model with a database of FAQs. LangChain’s strength lies in its ability to **customize every component**, from prompt engineering to output parsing, making it ideal for projects requiring high adaptability. However, this flexibility comes with a steeper learning curve, as it demands technical expertise in coding and API integration.\\n\\n**What is LangSmith?**  \\nIn contrast, **LangSmith** is a **platform** that focuses on collaboration and end-to-end AI development. It provides a user-friendly interface for teams to design, test, and deploy AI applications without needing to write extensive code. LangSmith’s features, such as **version control**, **real-time collaboration**, and **monitoring tools**, make it particularly appealing for organizations looking to scale AI solutions. For example, a product team might use LangSmith to prototype a customer support chatbot, iterating quickly with feedback from stakeholders. While LangSmith may not offer the same level of customization as LangChain, its emphasis on **simplicity and teamwork** makes it a powerful tool for non-technical users and cross-functional teams.\\n\\n**Key Differences Between LangChain and LangSmith**  \\nThe primary distinction between LangChain and LangSmith lies in their **purpose and target audience**. LangChain is a **developer-centric framework** for building AI applications with a focus on **modularity and customization**. It is best suited for projects where developers need to integrate multiple tools and models into a cohesive pipeline. On the other hand, LangSmith is a **collaborative platform** designed for **teams and organizations** that prioritize **efficiency, scalability, and ease of use**. While LangChain excels in technical flexibility, LangSmith shines in streamlining the AI development lifecycle for non-technical stakeholders. Additionally, LangChain requires **coding expertise**, whereas LangSmith’s **visual tools** lower the barrier to entry for users with varying skill levels.\\n\\n**When to Use Each Tool**  \\nChoosing between LangChain and LangSmith depends on the project’s requirements. If the goal is to create a highly customized AI application with fine-grained control over components, **LangChain** is the better choice. For example, a startup developing a niche AI tool for data analysis might prefer LangChain’s flexibility. Conversely, if the focus is on **collaboration, rapid iteration, and deployment**, **LangSmith** is more appropriate. A marketing team building a customer-facing AI assistant, for instance, might leverage LangSmith’s collaborative features to ensure alignment across departments.\\n\\n**Conclusion**  \\nIn summary, **LangChain** and **LangSmith** are complementary tools that address different aspects of AI development. LangChain’s strength lies in its **modular framework** for developers, while LangSmith’s value is in its **collaborative platform** for teams. Understanding these differences allows users to select the right tool based on their project’s complexity, team structure, and technical requirements. As AI continues to shape industries, tools like LangChain and LangSmith will remain critical in bridging the gap between innovation and implementation.', 'revision_number': 2}}\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!pip3 install -qU langgraph\n",
    "!pip3 install langgraph-checkpoint-sqlite\n",
    "!pip3 install tavily-python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from langchain_core.tools import Tool\n",
    "from pydantic import BaseModel, ValidationError\n",
    "#from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain.tools import tool\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from tavily import TavilyClient\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from IPython.display import Image\n",
    "import re\n",
    "\n",
    "\n",
    "# connect to tavily search tool\n",
    "os.environ['TAVILY_API_KEY']=\"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\"\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "#tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "#define agent state\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    lnode: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    queries: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    count: Annotated[int, operator.add]\n",
    "\n",
    "\n",
    "#define and configure the model\n",
    "# configure model\n",
    "httpx_client = httpx.Client(http2=True, verify=False, timeout=10.0)\n",
    "\n",
    "vcapservices = os.getenv('VCAP_SERVICES')\n",
    "services = json.loads(vcapservices)\n",
    "\n",
    "def is_chatservice(service):\n",
    "    return service[\"name\"] == \"gen-ai-qwen3-ultra\"\n",
    "\n",
    "chat_services = filter(is_chatservice, services[\"genai\"])\n",
    "chat_credentials = list(chat_services)[0][\"credentials\"]\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=chat_credentials[\"model_name\"], base_url=chat_credentials[\"api_base\"], api_key=chat_credentials[\"api_key\"], http_client=httpx_client)\n",
    "\n",
    "\n",
    "#define prompts\n",
    "PLAN_PROMPT = \"\"\"\n",
    "You are an expert writer tasked with writing a high level outline of an eassy. \\\n",
    "Write such an outline for the user provided topic. Give an outline of eassy along \\\n",
    "with any relevant notes or instructions for the sections.\n",
    "\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"\n",
    "You are an eassy assistant tasked with writing excellent 5-paragraph eassys. \\\n",
    "Generate the best eassy possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of ypur previous attempts. \\\n",
    "\n",
    "--------\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"\n",
    "You are a teacher grading an eassy submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\n",
    "\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"\n",
    "You are a researcher charged with providing information that can \\\n",
    "be used when writing the following eassy. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max\n",
    "\"\"\"\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"\n",
    "You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as oulined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. \\\n",
    "Only generate 3 queries max.\n",
    "\"\"\"\n",
    "    \n",
    "def extract_json(text):\n",
    "    # Remove unwanted tags like <think> and <speak>\n",
    "    cleaned_text = re.sub(r'<\\/?[\\w\\d]+>', '', text).strip()\n",
    "\n",
    "    # Now try to extract the JSON part using regex\n",
    "    match = re.search(r'\\{.*\\}', cleaned_text, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No JSON object found in response\")\n",
    "    return json.loads(match.group(0))\n",
    "    \n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]\n",
    "\n",
    "#implement nodes\n",
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT),\n",
    "        HumanMessage(content=state[\"task\"])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}\n",
    "    \n",
    "def research_plan_node(state: AgentState):\n",
    "    raw_response = model.invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        json_data = extract_json(raw_response.content if hasattr(raw_response, 'content') else str(raw_response))\n",
    "        queries = Queries.model_validate(json_data)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing JSON from model output:\", e)\n",
    "        return {\"content\": state.get('content', [])}\n",
    "\n",
    "    content = state.get('content', [])\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "\n",
    "    return {\"content\": content}\n",
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join([\"content\"] or [])\n",
    "    user_message = HumanMessage(content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
    "        user_message,\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1,\n",
    "    }\n",
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state['draft']),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}\n",
    "\n",
    "def research_critique_node(state: AgentState):\n",
    "    try:\n",
    "        # Run the model\n",
    "        raw_response = model.invoke([\n",
    "            SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "            HumanMessage(content=state['critique'])\n",
    "        ])\n",
    "        \n",
    "        # Extract JSON from model output (if Qwen adds extra tokens)\n",
    "        text_output = raw_response.content if isinstance(raw_response, AIMessage) else str(raw_response)\n",
    "        parsed = extract_json(text_output)\n",
    "        queries = Queries.model_validate(parsed)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during model invocation or JSON parsing:\", e)\n",
    "        return {\"content\": state.get(\"content\", [])}\n",
    "\n",
    "    content = state.get(\"content\", [])\n",
    "    for q in queries.queries:\n",
    "        try:\n",
    "            response = tavily.search(query=q, max_results=2)\n",
    "            for r in response.get(\"results\", []):\n",
    "                content.append(r.get(\"content\", \"\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed for query '{q}': {e}\")\n",
    "    \n",
    "    return {\"content\": content}\n",
    "\n",
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\"\n",
    "\n",
    "\n",
    "#build graph\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)\n",
    "\n",
    "#set entry point\n",
    "builder.set_entry_point(\"planner\")\n",
    "\n",
    "#define conditional edges\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n",
    "\n",
    "#define edges\n",
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")\n",
    "\n",
    "\n",
    "\n",
    "#print graph\n",
    "#Image(graph.get_graph().draw_png())\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    for s in graph.stream({\n",
    "        'task': \"what is the difference between langchain and langsmith\",\n",
    "        \"max_revisions\": 2,\n",
    "        \"revision_number\": 1,\n",
    "    }, thread):\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19911278-3bc6-4fc7-ae6b-ca125600f832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
